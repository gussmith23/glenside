#[version = "0.0.5"]
def @main(%images_0: Tensor[(1, 224, 224, 3), float32], %efficientnet_lite4_model_stem_conv2d_Conv2D_weights_fused_bn: Tensor[(32, 3, 3, 3), float32], %efficientnet_lite4_model_stem_conv2d_Conv2D_bias_fused_bn: Tensor[(32), float32], %efficientnet_lite4_model_head_tpu_batch_normalization_ReadVariableOp_1_0: Tensor[(1280), float32], %efficientnet_lite4_model_head_tpu_batch_normalization_ReadVariableOp_0: Tensor[(1280), float32], %efficientnet_lite4_model_head_tpu_batch_normalization_FusedBatchNormV3_ReadVariableOp_1_0: Tensor[(1280), float32], %efficientnet_lite4_model_head_tpu_batch_normalization_FusedBatchNormV3_ReadVariableOp_0: Tensor[(1280), float32], %efficientnet_lite4_model_head_dense_MatMul_ReadVariableOp_0: Tensor[(1280, 1000), float32], %efficientnet_lite4_model_head_dense_BiasAdd_ReadVariableOp_0: Tensor[(1000), float32], %efficientnet_lite4_model_head_conv2d_Conv2D_ReadVariableOp_0: Tensor[(1280, 448, 1, 1), float32], %efficientnet_lite4_model_blocks_9_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(336, 1, 3, 3), float32], %efficientnet_lite4_model_blocks_9_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(336), float32], %efficientnet_lite4_model_blocks_9_conv2d_1_Conv2D_weights_fused_bn: Tensor[(112, 336, 1, 1), float32], %efficientnet_lite4_model_blocks_9_conv2d_1_Conv2D_bias_fused_bn: Tensor[(112), float32], %efficientnet_lite4_model_blocks_9_conv2d_Conv2D_weights_fused_bn: Tensor[(336, 56, 1, 1), float32], %efficientnet_lite4_model_blocks_9_conv2d_Conv2D_bias_fused_bn: Tensor[(336), float32], %efficientnet_lite4_model_blocks_8_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(336, 1, 5, 5), float32], %efficientnet_lite4_model_blocks_8_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(336), float32], %efficientnet_lite4_model_blocks_8_conv2d_1_Conv2D_weights_fused_bn: Tensor[(56, 336, 1, 1), float32], %efficientnet_lite4_model_blocks_8_conv2d_1_Conv2D_bias_fused_bn: Tensor[(56), float32], %efficientnet_lite4_model_blocks_8_conv2d_Conv2D_weights_fused_bn: Tensor[(336, 56, 1, 1), float32], %efficientnet_lite4_model_blocks_8_conv2d_Conv2D_bias_fused_bn: Tensor[(336), float32], %efficientnet_lite4_model_blocks_7_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(336, 1, 5, 5), float32], %efficientnet_lite4_model_blocks_7_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(336), float32], %efficientnet_lite4_model_blocks_7_conv2d_1_Conv2D_weights_fused_bn: Tensor[(56, 336, 1, 1), float32], %efficientnet_lite4_model_blocks_7_conv2d_1_Conv2D_bias_fused_bn: Tensor[(56), float32], %efficientnet_lite4_model_blocks_7_conv2d_Conv2D_weights_fused_bn: Tensor[(336, 56, 1, 1), float32], %efficientnet_lite4_model_blocks_7_conv2d_Conv2D_bias_fused_bn: Tensor[(336), float32], %efficientnet_lite4_model_blocks_6_tpu_batch_normalization_ReadVariableOp_1_0: Tensor[(336), float32], %efficientnet_lite4_model_blocks_6_tpu_batch_normalization_ReadVariableOp_0: Tensor[(336), float32], %efficientnet_lite4_model_blocks_6_tpu_batch_normalization_FusedBatchNormV3_ReadVariableOp_1_0: Tensor[(336), float32], %efficientnet_lite4_model_blocks_6_tpu_batch_normalization_FusedBatchNormV3_ReadVariableOp_0: Tensor[(336), float32], %efficientnet_lite4_model_blocks_6_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(336, 1, 5, 5), float32], %efficientnet_lite4_model_blocks_6_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(336), float32], %efficientnet_lite4_model_blocks_6_conv2d_1_Conv2D_weights_fused_bn: Tensor[(56, 336, 1, 1), float32], %efficientnet_lite4_model_blocks_6_conv2d_1_Conv2D_bias_fused_bn: Tensor[(56), float32], %efficientnet_lite4_model_blocks_6_conv2d_Conv2D_ReadVariableOp_0: Tensor[(336, 56, 1, 1), float32], %efficientnet_lite4_model_blocks_5_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(192, 1, 5, 5), float32], %efficientnet_lite4_model_blocks_5_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(192), float32], %efficientnet_lite4_model_blocks_5_conv2d_1_Conv2D_weights_fused_bn: Tensor[(56, 192, 1, 1), float32], %efficientnet_lite4_model_blocks_5_conv2d_1_Conv2D_bias_fused_bn: Tensor[(56), float32], %efficientnet_lite4_model_blocks_5_conv2d_Conv2D_weights_fused_bn: Tensor[(192, 32, 1, 1), float32], %efficientnet_lite4_model_blocks_5_conv2d_Conv2D_bias_fused_bn: Tensor[(192), float32], %efficientnet_lite4_model_blocks_4_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(192, 1, 3, 3), float32], %efficientnet_lite4_model_blocks_4_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(192), float32], %efficientnet_lite4_model_blocks_4_conv2d_1_Conv2D_weights_fused_bn: Tensor[(32, 192, 1, 1), float32], %efficientnet_lite4_model_blocks_4_conv2d_1_Conv2D_bias_fused_bn: Tensor[(32), float32], %efficientnet_lite4_model_blocks_4_conv2d_Conv2D_weights_fused_bn: Tensor[(192, 32, 1, 1), float32], %efficientnet_lite4_model_blocks_4_conv2d_Conv2D_bias_fused_bn: Tensor[(192), float32], %efficientnet_lite4_model_blocks_3_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(192, 1, 3, 3), float32], %efficientnet_lite4_model_blocks_3_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(192), float32], %efficientnet_lite4_model_blocks_3_conv2d_1_Conv2D_weights_fused_bn: Tensor[(32, 192, 1, 1), float32], %efficientnet_lite4_model_blocks_3_conv2d_1_Conv2D_bias_fused_bn: Tensor[(32), float32], %efficientnet_lite4_model_blocks_3_conv2d_Conv2D_weights_fused_bn: Tensor[(192, 32, 1, 1), float32], %efficientnet_lite4_model_blocks_3_conv2d_Conv2D_bias_fused_bn: Tensor[(192), float32], %efficientnet_lite4_model_blocks_29_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(1632, 1, 3, 3), float32], %efficientnet_lite4_model_blocks_29_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(1632), float32], %efficientnet_lite4_model_blocks_29_conv2d_1_Conv2D_weights_fused_bn: Tensor[(448, 1632, 1, 1), float32], %efficientnet_lite4_model_blocks_29_conv2d_1_Conv2D_bias_fused_bn: Tensor[(448), float32], %efficientnet_lite4_model_blocks_29_conv2d_Conv2D_weights_fused_bn: Tensor[(1632, 272, 1, 1), float32], %efficientnet_lite4_model_blocks_29_conv2d_Conv2D_bias_fused_bn: Tensor[(1632), float32], %efficientnet_lite4_model_blocks_29_Relu6_1_min__569: float32, %efficientnet_lite4_model_blocks_28_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(1632, 1, 5, 5), float32], %efficientnet_lite4_model_blocks_28_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(1632), float32], %efficientnet_lite4_model_blocks_28_conv2d_1_Conv2D_weights_fused_bn: Tensor[(272, 1632, 1, 1), float32], %efficientnet_lite4_model_blocks_28_conv2d_1_Conv2D_bias_fused_bn: Tensor[(272), float32], %efficientnet_lite4_model_blocks_28_conv2d_Conv2D_weights_fused_bn: Tensor[(1632, 272, 1, 1), float32], %efficientnet_lite4_model_blocks_28_conv2d_Conv2D_bias_fused_bn: Tensor[(1632), float32], %efficientnet_lite4_model_blocks_27_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(1632, 1, 5, 5), float32], %efficientnet_lite4_model_blocks_27_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(1632), float32], %efficientnet_lite4_model_blocks_27_conv2d_1_Conv2D_weights_fused_bn: Tensor[(272, 1632, 1, 1), float32], %efficientnet_lite4_model_blocks_27_conv2d_1_Conv2D_bias_fused_bn: Tensor[(272), float32], %efficientnet_lite4_model_blocks_27_conv2d_Conv2D_weights_fused_bn: Tensor[(1632, 272, 1, 1), float32], %efficientnet_lite4_model_blocks_27_conv2d_Conv2D_bias_fused_bn: Tensor[(1632), float32], %efficientnet_lite4_model_blocks_26_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(1632, 1, 5, 5), float32], %efficientnet_lite4_model_blocks_26_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(1632), float32], %efficientnet_lite4_model_blocks_26_conv2d_1_Conv2D_weights_fused_bn: Tensor[(272, 1632, 1, 1), float32], %efficientnet_lite4_model_blocks_26_conv2d_1_Conv2D_bias_fused_bn: Tensor[(272), float32], %efficientnet_lite4_model_blocks_26_conv2d_Conv2D_weights_fused_bn: Tensor[(1632, 272, 1, 1), float32], %efficientnet_lite4_model_blocks_26_conv2d_Conv2D_bias_fused_bn: Tensor[(1632), float32], %efficientnet_lite4_model_blocks_25_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(1632, 1, 5, 5), float32], %efficientnet_lite4_model_blocks_25_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(1632), float32], %efficientnet_lite4_model_blocks_25_conv2d_1_Conv2D_weights_fused_bn: Tensor[(272, 1632, 1, 1), float32], %efficientnet_lite4_model_blocks_25_conv2d_1_Conv2D_bias_fused_bn: Tensor[(272), float32], %efficientnet_lite4_model_blocks_25_conv2d_Conv2D_weights_fused_bn: Tensor[(1632, 272, 1, 1), float32], %efficientnet_lite4_model_blocks_25_conv2d_Conv2D_bias_fused_bn: Tensor[(1632), float32], %efficientnet_lite4_model_blocks_24_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(1632, 1, 5, 5), float32], %efficientnet_lite4_model_blocks_24_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(1632), float32], %efficientnet_lite4_model_blocks_24_conv2d_1_Conv2D_weights_fused_bn: Tensor[(272, 1632, 1, 1), float32], %efficientnet_lite4_model_blocks_24_conv2d_1_Conv2D_bias_fused_bn: Tensor[(272), float32], %efficientnet_lite4_model_blocks_24_conv2d_Conv2D_weights_fused_bn: Tensor[(1632, 272, 1, 1), float32], %efficientnet_lite4_model_blocks_24_conv2d_Conv2D_bias_fused_bn: Tensor[(1632), float32], %efficientnet_lite4_model_blocks_23_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(1632, 1, 5, 5), float32], %efficientnet_lite4_model_blocks_23_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(1632), float32], %efficientnet_lite4_model_blocks_23_conv2d_1_Conv2D_weights_fused_bn: Tensor[(272, 1632, 1, 1), float32], %efficientnet_lite4_model_blocks_23_conv2d_1_Conv2D_bias_fused_bn: Tensor[(272), float32], %efficientnet_lite4_model_blocks_23_conv2d_Conv2D_weights_fused_bn: Tensor[(1632, 272, 1, 1), float32], %efficientnet_lite4_model_blocks_23_conv2d_Conv2D_bias_fused_bn: Tensor[(1632), float32], %efficientnet_lite4_model_blocks_22_tpu_batch_normalization_ReadVariableOp_1_0: Tensor[(1632), float32], %efficientnet_lite4_model_blocks_22_tpu_batch_normalization_ReadVariableOp_0: Tensor[(1632), float32], %efficientnet_lite4_model_blocks_22_tpu_batch_normalization_FusedBatchNormV3_ReadVariableOp_1_0: Tensor[(1632), float32], %efficientnet_lite4_model_blocks_22_tpu_batch_normalization_FusedBatchNormV3_ReadVariableOp_0: Tensor[(1632), float32], %efficientnet_lite4_model_blocks_22_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(1632, 1, 5, 5), float32], %efficientnet_lite4_model_blocks_22_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(1632), float32], %efficientnet_lite4_model_blocks_22_conv2d_1_Conv2D_weights_fused_bn: Tensor[(272, 1632, 1, 1), float32], %efficientnet_lite4_model_blocks_22_conv2d_1_Conv2D_bias_fused_bn: Tensor[(272), float32], %efficientnet_lite4_model_blocks_22_conv2d_Conv2D_ReadVariableOp_0: Tensor[(1632, 272, 1, 1), float32], %efficientnet_lite4_model_blocks_21_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(960, 1, 5, 5), float32], %efficientnet_lite4_model_blocks_21_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(960), float32], %efficientnet_lite4_model_blocks_21_conv2d_1_Conv2D_weights_fused_bn: Tensor[(272, 960, 1, 1), float32], %efficientnet_lite4_model_blocks_21_conv2d_1_Conv2D_bias_fused_bn: Tensor[(272), float32], %efficientnet_lite4_model_blocks_21_conv2d_Conv2D_weights_fused_bn: Tensor[(960, 160, 1, 1), float32], %efficientnet_lite4_model_blocks_21_conv2d_Conv2D_bias_fused_bn: Tensor[(960), float32], %efficientnet_lite4_model_blocks_20_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(960, 1, 5, 5), float32], %efficientnet_lite4_model_blocks_20_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(960), float32], %efficientnet_lite4_model_blocks_20_conv2d_1_Conv2D_weights_fused_bn: Tensor[(160, 960, 1, 1), float32], %efficientnet_lite4_model_blocks_20_conv2d_1_Conv2D_bias_fused_bn: Tensor[(160), float32], %efficientnet_lite4_model_blocks_20_conv2d_Conv2D_weights_fused_bn: Tensor[(960, 160, 1, 1), float32], %efficientnet_lite4_model_blocks_20_conv2d_Conv2D_bias_fused_bn: Tensor[(960), float32], %efficientnet_lite4_model_blocks_2_tpu_batch_normalization_ReadVariableOp_1_0: Tensor[(192), float32], %efficientnet_lite4_model_blocks_2_tpu_batch_normalization_ReadVariableOp_0: Tensor[(192), float32], %efficientnet_lite4_model_blocks_2_tpu_batch_normalization_FusedBatchNormV3_ReadVariableOp_1_0: Tensor[(192), float32], %efficientnet_lite4_model_blocks_2_tpu_batch_normalization_FusedBatchNormV3_ReadVariableOp_0: Tensor[(192), float32], %efficientnet_lite4_model_blocks_2_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(192, 1, 3, 3), float32], %efficientnet_lite4_model_blocks_2_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(192), float32], %efficientnet_lite4_model_blocks_2_conv2d_1_Conv2D_weights_fused_bn: Tensor[(32, 192, 1, 1), float32], %efficientnet_lite4_model_blocks_2_conv2d_1_Conv2D_bias_fused_bn: Tensor[(32), float32], %efficientnet_lite4_model_blocks_2_conv2d_Conv2D_ReadVariableOp_0: Tensor[(192, 32, 1, 1), float32], %efficientnet_lite4_model_blocks_19_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(960, 1, 5, 5), float32], %efficientnet_lite4_model_blocks_19_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(960), float32], %efficientnet_lite4_model_blocks_19_conv2d_1_Conv2D_weights_fused_bn: Tensor[(160, 960, 1, 1), float32], %efficientnet_lite4_model_blocks_19_conv2d_1_Conv2D_bias_fused_bn: Tensor[(160), float32], %efficientnet_lite4_model_blocks_19_conv2d_Conv2D_weights_fused_bn: Tensor[(960, 160, 1, 1), float32], %efficientnet_lite4_model_blocks_19_conv2d_Conv2D_bias_fused_bn: Tensor[(960), float32], %efficientnet_lite4_model_blocks_19_Relu6_1_max__380: float32, %efficientnet_lite4_model_blocks_18_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(960, 1, 5, 5), float32], %efficientnet_lite4_model_blocks_18_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(960), float32], %efficientnet_lite4_model_blocks_18_conv2d_1_Conv2D_weights_fused_bn: Tensor[(160, 960, 1, 1), float32], %efficientnet_lite4_model_blocks_18_conv2d_1_Conv2D_bias_fused_bn: Tensor[(160), float32], %efficientnet_lite4_model_blocks_18_conv2d_Conv2D_weights_fused_bn: Tensor[(960, 160, 1, 1), float32], %efficientnet_lite4_model_blocks_18_conv2d_Conv2D_bias_fused_bn: Tensor[(960), float32], %efficientnet_lite4_model_blocks_17_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(960, 1, 5, 5), float32], %efficientnet_lite4_model_blocks_17_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(960), float32], %efficientnet_lite4_model_blocks_17_conv2d_1_Conv2D_weights_fused_bn: Tensor[(160, 960, 1, 1), float32], %efficientnet_lite4_model_blocks_17_conv2d_1_Conv2D_bias_fused_bn: Tensor[(160), float32], %efficientnet_lite4_model_blocks_17_conv2d_Conv2D_weights_fused_bn: Tensor[(960, 160, 1, 1), float32], %efficientnet_lite4_model_blocks_17_conv2d_Conv2D_bias_fused_bn: Tensor[(960), float32], %efficientnet_lite4_model_blocks_16_tpu_batch_normalization_ReadVariableOp_1_0: Tensor[(960), float32], %efficientnet_lite4_model_blocks_16_tpu_batch_normalization_ReadVariableOp_0: Tensor[(960), float32], %efficientnet_lite4_model_blocks_16_tpu_batch_normalization_FusedBatchNormV3_ReadVariableOp_1_0: Tensor[(960), float32], %efficientnet_lite4_model_blocks_16_tpu_batch_normalization_FusedBatchNormV3_ReadVariableOp_0: Tensor[(960), float32], %efficientnet_lite4_model_blocks_16_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(960, 1, 5, 5), float32], %efficientnet_lite4_model_blocks_16_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(960), float32], %efficientnet_lite4_model_blocks_16_conv2d_1_Conv2D_weights_fused_bn: Tensor[(160, 960, 1, 1), float32], %efficientnet_lite4_model_blocks_16_conv2d_1_Conv2D_bias_fused_bn: Tensor[(160), float32], %efficientnet_lite4_model_blocks_16_conv2d_Conv2D_ReadVariableOp_0: Tensor[(960, 160, 1, 1), float32], %efficientnet_lite4_model_blocks_15_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(672, 1, 5, 5), float32], %efficientnet_lite4_model_blocks_15_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(672), float32], %efficientnet_lite4_model_blocks_15_conv2d_1_Conv2D_weights_fused_bn: Tensor[(160, 672, 1, 1), float32], %efficientnet_lite4_model_blocks_15_conv2d_1_Conv2D_bias_fused_bn: Tensor[(160), float32], %efficientnet_lite4_model_blocks_15_conv2d_Conv2D_weights_fused_bn: Tensor[(672, 112, 1, 1), float32], %efficientnet_lite4_model_blocks_15_conv2d_Conv2D_bias_fused_bn: Tensor[(672), float32], %efficientnet_lite4_model_blocks_14_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(672, 1, 3, 3), float32], %efficientnet_lite4_model_blocks_14_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(672), float32], %efficientnet_lite4_model_blocks_14_conv2d_1_Conv2D_weights_fused_bn: Tensor[(112, 672, 1, 1), float32], %efficientnet_lite4_model_blocks_14_conv2d_1_Conv2D_bias_fused_bn: Tensor[(112), float32], %efficientnet_lite4_model_blocks_14_conv2d_Conv2D_weights_fused_bn: Tensor[(672, 112, 1, 1), float32], %efficientnet_lite4_model_blocks_14_conv2d_Conv2D_bias_fused_bn: Tensor[(672), float32], %efficientnet_lite4_model_blocks_13_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(672, 1, 3, 3), float32], %efficientnet_lite4_model_blocks_13_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(672), float32], %efficientnet_lite4_model_blocks_13_conv2d_1_Conv2D_weights_fused_bn: Tensor[(112, 672, 1, 1), float32], %efficientnet_lite4_model_blocks_13_conv2d_1_Conv2D_bias_fused_bn: Tensor[(112), float32], %efficientnet_lite4_model_blocks_13_conv2d_Conv2D_weights_fused_bn: Tensor[(672, 112, 1, 1), float32], %efficientnet_lite4_model_blocks_13_conv2d_Conv2D_bias_fused_bn: Tensor[(672), float32], %efficientnet_lite4_model_blocks_12_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(672, 1, 3, 3), float32], %efficientnet_lite4_model_blocks_12_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(672), float32], %efficientnet_lite4_model_blocks_12_conv2d_1_Conv2D_weights_fused_bn: Tensor[(112, 672, 1, 1), float32], %efficientnet_lite4_model_blocks_12_conv2d_1_Conv2D_bias_fused_bn: Tensor[(112), float32], %efficientnet_lite4_model_blocks_12_conv2d_Conv2D_weights_fused_bn: Tensor[(672, 112, 1, 1), float32], %efficientnet_lite4_model_blocks_12_conv2d_Conv2D_bias_fused_bn: Tensor[(672), float32], %efficientnet_lite4_model_blocks_11_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(672, 1, 3, 3), float32], %efficientnet_lite4_model_blocks_11_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(672), float32], %efficientnet_lite4_model_blocks_11_conv2d_1_Conv2D_weights_fused_bn: Tensor[(112, 672, 1, 1), float32], %efficientnet_lite4_model_blocks_11_conv2d_1_Conv2D_bias_fused_bn: Tensor[(112), float32], %efficientnet_lite4_model_blocks_11_conv2d_Conv2D_weights_fused_bn: Tensor[(672, 112, 1, 1), float32], %efficientnet_lite4_model_blocks_11_conv2d_Conv2D_bias_fused_bn: Tensor[(672), float32], %efficientnet_lite4_model_blocks_10_tpu_batch_normalization_ReadVariableOp_1_0: Tensor[(672), float32], %efficientnet_lite4_model_blocks_10_tpu_batch_normalization_ReadVariableOp_0: Tensor[(672), float32], %efficientnet_lite4_model_blocks_10_tpu_batch_normalization_FusedBatchNormV3_ReadVariableOp_1_0: Tensor[(672), float32], %efficientnet_lite4_model_blocks_10_tpu_batch_normalization_FusedBatchNormV3_ReadVariableOp_0: Tensor[(672), float32], %efficientnet_lite4_model_blocks_10_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(672, 1, 3, 3), float32], %efficientnet_lite4_model_blocks_10_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(672), float32], %efficientnet_lite4_model_blocks_10_conv2d_1_Conv2D_weights_fused_bn: Tensor[(112, 672, 1, 1), float32], %efficientnet_lite4_model_blocks_10_conv2d_1_Conv2D_bias_fused_bn: Tensor[(112), float32], %efficientnet_lite4_model_blocks_10_conv2d_Conv2D_ReadVariableOp_0: Tensor[(672, 112, 1, 1), float32], %efficientnet_lite4_model_blocks_1_tpu_batch_normalization_ReadVariableOp_1_0: Tensor[(144), float32], %efficientnet_lite4_model_blocks_1_tpu_batch_normalization_ReadVariableOp_0: Tensor[(144), float32], %efficientnet_lite4_model_blocks_1_tpu_batch_normalization_FusedBatchNormV3_ReadVariableOp_1_0: Tensor[(144), float32], %efficientnet_lite4_model_blocks_1_tpu_batch_normalization_FusedBatchNormV3_ReadVariableOp_0: Tensor[(144), float32], %efficientnet_lite4_model_blocks_1_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(144, 1, 3, 3), float32], %efficientnet_lite4_model_blocks_1_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(144), float32], %efficientnet_lite4_model_blocks_1_conv2d_1_Conv2D_weights_fused_bn: Tensor[(32, 144, 1, 1), float32], %efficientnet_lite4_model_blocks_1_conv2d_1_Conv2D_bias_fused_bn: Tensor[(32), float32], %efficientnet_lite4_model_blocks_1_conv2d_Conv2D_ReadVariableOp_0: Tensor[(144, 24, 1, 1), float32], %efficientnet_lite4_model_blocks_0_depthwise_conv2d_depthwise_weights_fused_bn: Tensor[(32, 1, 3, 3), float32], %efficientnet_lite4_model_blocks_0_depthwise_conv2d_depthwise_bias_fused_bn: Tensor[(32), float32], %efficientnet_lite4_model_blocks_0_conv2d_Conv2D_weights_fused_bn: Tensor[(24, 32, 1, 1), float32], %efficientnet_lite4_model_blocks_0_conv2d_Conv2D_bias_fused_bn: Tensor[(24), float32]) -> Tensor[(1, 1000), float32] {
  %0 = transpose(%images_0, axes=[0, 3, 1, 2]);
  %1 = nn.conv2d(%0, %efficientnet_lite4_model_stem_conv2d_Conv2D_weights_fused_bn, strides=[2, 2], padding=[0, 0, 1, 1], kernel_size=[3, 3]);
  %2 = nn.bias_add(%1, %efficientnet_lite4_model_stem_conv2d_Conv2D_bias_fused_bn);
  %3 = maximum(%2, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %4 = minimum(%3, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %5 = nn.conv2d(%4, %efficientnet_lite4_model_blocks_0_depthwise_conv2d_depthwise_weights_fused_bn, padding=[1, 1, 1, 1], groups=32, kernel_size=[3, 3]);
  %6 = nn.bias_add(%5, %efficientnet_lite4_model_blocks_0_depthwise_conv2d_depthwise_bias_fused_bn);
  %7 = maximum(%6, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %8 = minimum(%7, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %9 = nn.conv2d(%8, %efficientnet_lite4_model_blocks_0_conv2d_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %10 = nn.bias_add(%9, %efficientnet_lite4_model_blocks_0_conv2d_Conv2D_bias_fused_bn);
  %11 = nn.conv2d(%10, %efficientnet_lite4_model_blocks_1_conv2d_Conv2D_ReadVariableOp_0, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %12 = nn.batch_norm(%11, %efficientnet_lite4_model_blocks_1_tpu_batch_normalization_ReadVariableOp_0, %efficientnet_lite4_model_blocks_1_tpu_batch_normalization_ReadVariableOp_1_0, %efficientnet_lite4_model_blocks_1_tpu_batch_normalization_FusedBatchNormV3_ReadVariableOp_0, %efficientnet_lite4_model_blocks_1_tpu_batch_normalization_FusedBatchNormV3_ReadVariableOp_1_0, epsilon=0.001f);
  %13 = %12.0;
  %14 = maximum(%13, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %15 = minimum(%14, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %16 = nn.conv2d(%15, %efficientnet_lite4_model_blocks_1_depthwise_conv2d_depthwise_weights_fused_bn, strides=[2, 2], padding=[0, 0, 1, 1], groups=144, kernel_size=[3, 3]);
  %17 = nn.bias_add(%16, %efficientnet_lite4_model_blocks_1_depthwise_conv2d_depthwise_bias_fused_bn);
  %18 = maximum(%17, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %19 = minimum(%18, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %20 = nn.conv2d(%19, %efficientnet_lite4_model_blocks_1_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %21 = nn.bias_add(%20, %efficientnet_lite4_model_blocks_1_conv2d_1_Conv2D_bias_fused_bn);
  %22 = nn.conv2d(%21, %efficientnet_lite4_model_blocks_2_conv2d_Conv2D_ReadVariableOp_0, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %23 = nn.batch_norm(%22, %efficientnet_lite4_model_blocks_2_tpu_batch_normalization_ReadVariableOp_0, %efficientnet_lite4_model_blocks_2_tpu_batch_normalization_ReadVariableOp_1_0, %efficientnet_lite4_model_blocks_2_tpu_batch_normalization_FusedBatchNormV3_ReadVariableOp_0, %efficientnet_lite4_model_blocks_2_tpu_batch_normalization_FusedBatchNormV3_ReadVariableOp_1_0, epsilon=0.001f);
  %24 = %23.0;
  %25 = maximum(%24, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %26 = minimum(%25, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %27 = nn.conv2d(%26, %efficientnet_lite4_model_blocks_2_depthwise_conv2d_depthwise_weights_fused_bn, padding=[1, 1, 1, 1], groups=192, kernel_size=[3, 3]);
  %28 = nn.bias_add(%27, %efficientnet_lite4_model_blocks_2_depthwise_conv2d_depthwise_bias_fused_bn);
  %29 = maximum(%28, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %30 = minimum(%29, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %31 = nn.conv2d(%30, %efficientnet_lite4_model_blocks_2_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %32 = nn.bias_add(%31, %efficientnet_lite4_model_blocks_2_conv2d_1_Conv2D_bias_fused_bn);
  %33 = add(%32, %21);
  %34 = nn.conv2d(%33, %efficientnet_lite4_model_blocks_3_conv2d_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %35 = nn.bias_add(%34, %efficientnet_lite4_model_blocks_3_conv2d_Conv2D_bias_fused_bn);
  %36 = maximum(%35, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %37 = minimum(%36, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %38 = nn.conv2d(%37, %efficientnet_lite4_model_blocks_3_depthwise_conv2d_depthwise_weights_fused_bn, padding=[1, 1, 1, 1], groups=192, kernel_size=[3, 3]);
  %39 = nn.bias_add(%38, %efficientnet_lite4_model_blocks_3_depthwise_conv2d_depthwise_bias_fused_bn);
  %40 = maximum(%39, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %41 = minimum(%40, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %42 = nn.conv2d(%41, %efficientnet_lite4_model_blocks_3_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %43 = nn.bias_add(%42, %efficientnet_lite4_model_blocks_3_conv2d_1_Conv2D_bias_fused_bn);
  %44 = add(%43, %33);
  %45 = nn.conv2d(%44, %efficientnet_lite4_model_blocks_4_conv2d_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %46 = nn.bias_add(%45, %efficientnet_lite4_model_blocks_4_conv2d_Conv2D_bias_fused_bn);
  %47 = maximum(%46, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %48 = minimum(%47, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %49 = nn.conv2d(%48, %efficientnet_lite4_model_blocks_4_depthwise_conv2d_depthwise_weights_fused_bn, padding=[1, 1, 1, 1], groups=192, kernel_size=[3, 3]);
  %50 = nn.bias_add(%49, %efficientnet_lite4_model_blocks_4_depthwise_conv2d_depthwise_bias_fused_bn);
  %51 = maximum(%50, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %52 = minimum(%51, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %53 = nn.conv2d(%52, %efficientnet_lite4_model_blocks_4_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %54 = nn.bias_add(%53, %efficientnet_lite4_model_blocks_4_conv2d_1_Conv2D_bias_fused_bn);
  %55 = add(%54, %44);
  %56 = nn.conv2d(%55, %efficientnet_lite4_model_blocks_5_conv2d_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %57 = nn.bias_add(%56, %efficientnet_lite4_model_blocks_5_conv2d_Conv2D_bias_fused_bn);
  %58 = maximum(%57, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %59 = minimum(%58, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %60 = nn.conv2d(%59, %efficientnet_lite4_model_blocks_5_depthwise_conv2d_depthwise_weights_fused_bn, strides=[2, 2], padding=[1, 1, 2, 2], groups=192, kernel_size=[5, 5]);
  %61 = nn.bias_add(%60, %efficientnet_lite4_model_blocks_5_depthwise_conv2d_depthwise_bias_fused_bn);
  %62 = maximum(%61, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %63 = minimum(%62, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %64 = nn.conv2d(%63, %efficientnet_lite4_model_blocks_5_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %65 = nn.bias_add(%64, %efficientnet_lite4_model_blocks_5_conv2d_1_Conv2D_bias_fused_bn);
  %66 = nn.conv2d(%65, %efficientnet_lite4_model_blocks_6_conv2d_Conv2D_ReadVariableOp_0, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %67 = nn.batch_norm(%66, %efficientnet_lite4_model_blocks_6_tpu_batch_normalization_ReadVariableOp_0, %efficientnet_lite4_model_blocks_6_tpu_batch_normalization_ReadVariableOp_1_0, %efficientnet_lite4_model_blocks_6_tpu_batch_normalization_FusedBatchNormV3_ReadVariableOp_0, %efficientnet_lite4_model_blocks_6_tpu_batch_normalization_FusedBatchNormV3_ReadVariableOp_1_0, epsilon=0.001f);
  %68 = %67.0;
  %69 = maximum(%68, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %70 = minimum(%69, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %71 = nn.conv2d(%70, %efficientnet_lite4_model_blocks_6_depthwise_conv2d_depthwise_weights_fused_bn, padding=[2, 2, 2, 2], groups=336, kernel_size=[5, 5]);
  %72 = nn.bias_add(%71, %efficientnet_lite4_model_blocks_6_depthwise_conv2d_depthwise_bias_fused_bn);
  %73 = maximum(%72, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %74 = minimum(%73, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %75 = nn.conv2d(%74, %efficientnet_lite4_model_blocks_6_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %76 = nn.bias_add(%75, %efficientnet_lite4_model_blocks_6_conv2d_1_Conv2D_bias_fused_bn);
  %77 = add(%76, %65);
  %78 = nn.conv2d(%77, %efficientnet_lite4_model_blocks_7_conv2d_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %79 = nn.bias_add(%78, %efficientnet_lite4_model_blocks_7_conv2d_Conv2D_bias_fused_bn);
  %80 = maximum(%79, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %81 = minimum(%80, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %82 = nn.conv2d(%81, %efficientnet_lite4_model_blocks_7_depthwise_conv2d_depthwise_weights_fused_bn, padding=[2, 2, 2, 2], groups=336, kernel_size=[5, 5]);
  %83 = nn.bias_add(%82, %efficientnet_lite4_model_blocks_7_depthwise_conv2d_depthwise_bias_fused_bn);
  %84 = maximum(%83, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %85 = minimum(%84, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %86 = nn.conv2d(%85, %efficientnet_lite4_model_blocks_7_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %87 = nn.bias_add(%86, %efficientnet_lite4_model_blocks_7_conv2d_1_Conv2D_bias_fused_bn);
  %88 = add(%87, %77);
  %89 = nn.conv2d(%88, %efficientnet_lite4_model_blocks_8_conv2d_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %90 = nn.bias_add(%89, %efficientnet_lite4_model_blocks_8_conv2d_Conv2D_bias_fused_bn);
  %91 = maximum(%90, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %92 = minimum(%91, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %93 = nn.conv2d(%92, %efficientnet_lite4_model_blocks_8_depthwise_conv2d_depthwise_weights_fused_bn, padding=[2, 2, 2, 2], groups=336, kernel_size=[5, 5]);
  %94 = nn.bias_add(%93, %efficientnet_lite4_model_blocks_8_depthwise_conv2d_depthwise_bias_fused_bn);
  %95 = maximum(%94, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %96 = minimum(%95, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %97 = nn.conv2d(%96, %efficientnet_lite4_model_blocks_8_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %98 = nn.bias_add(%97, %efficientnet_lite4_model_blocks_8_conv2d_1_Conv2D_bias_fused_bn);
  %99 = add(%98, %88);
  %100 = nn.conv2d(%99, %efficientnet_lite4_model_blocks_9_conv2d_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %101 = nn.bias_add(%100, %efficientnet_lite4_model_blocks_9_conv2d_Conv2D_bias_fused_bn);
  %102 = maximum(%101, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %103 = minimum(%102, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %104 = nn.conv2d(%103, %efficientnet_lite4_model_blocks_9_depthwise_conv2d_depthwise_weights_fused_bn, strides=[2, 2], padding=[0, 0, 1, 1], groups=336, kernel_size=[3, 3]);
  %105 = nn.bias_add(%104, %efficientnet_lite4_model_blocks_9_depthwise_conv2d_depthwise_bias_fused_bn);
  %106 = maximum(%105, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %107 = minimum(%106, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %108 = nn.conv2d(%107, %efficientnet_lite4_model_blocks_9_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %109 = nn.bias_add(%108, %efficientnet_lite4_model_blocks_9_conv2d_1_Conv2D_bias_fused_bn);
  %110 = nn.conv2d(%109, %efficientnet_lite4_model_blocks_10_conv2d_Conv2D_ReadVariableOp_0, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %111 = nn.batch_norm(%110, %efficientnet_lite4_model_blocks_10_tpu_batch_normalization_ReadVariableOp_0, %efficientnet_lite4_model_blocks_10_tpu_batch_normalization_ReadVariableOp_1_0, %efficientnet_lite4_model_blocks_10_tpu_batch_normalization_FusedBatchNormV3_ReadVariableOp_0, %efficientnet_lite4_model_blocks_10_tpu_batch_normalization_FusedBatchNormV3_ReadVariableOp_1_0, epsilon=0.001f);
  %112 = %111.0;
  %113 = maximum(%112, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %114 = minimum(%113, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %115 = nn.conv2d(%114, %efficientnet_lite4_model_blocks_10_depthwise_conv2d_depthwise_weights_fused_bn, padding=[1, 1, 1, 1], groups=672, kernel_size=[3, 3]);
  %116 = nn.bias_add(%115, %efficientnet_lite4_model_blocks_10_depthwise_conv2d_depthwise_bias_fused_bn);
  %117 = maximum(%116, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %118 = minimum(%117, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %119 = nn.conv2d(%118, %efficientnet_lite4_model_blocks_10_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %120 = nn.bias_add(%119, %efficientnet_lite4_model_blocks_10_conv2d_1_Conv2D_bias_fused_bn);
  %121 = add(%120, %109);
  %122 = nn.conv2d(%121, %efficientnet_lite4_model_blocks_11_conv2d_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %123 = nn.bias_add(%122, %efficientnet_lite4_model_blocks_11_conv2d_Conv2D_bias_fused_bn);
  %124 = maximum(%123, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %125 = minimum(%124, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %126 = nn.conv2d(%125, %efficientnet_lite4_model_blocks_11_depthwise_conv2d_depthwise_weights_fused_bn, padding=[1, 1, 1, 1], groups=672, kernel_size=[3, 3]);
  %127 = nn.bias_add(%126, %efficientnet_lite4_model_blocks_11_depthwise_conv2d_depthwise_bias_fused_bn);
  %128 = maximum(%127, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %129 = minimum(%128, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %130 = nn.conv2d(%129, %efficientnet_lite4_model_blocks_11_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %131 = nn.bias_add(%130, %efficientnet_lite4_model_blocks_11_conv2d_1_Conv2D_bias_fused_bn);
  %132 = add(%131, %121);
  %133 = nn.conv2d(%132, %efficientnet_lite4_model_blocks_12_conv2d_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %134 = nn.bias_add(%133, %efficientnet_lite4_model_blocks_12_conv2d_Conv2D_bias_fused_bn);
  %135 = maximum(%134, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %136 = minimum(%135, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %137 = nn.conv2d(%136, %efficientnet_lite4_model_blocks_12_depthwise_conv2d_depthwise_weights_fused_bn, padding=[1, 1, 1, 1], groups=672, kernel_size=[3, 3]);
  %138 = nn.bias_add(%137, %efficientnet_lite4_model_blocks_12_depthwise_conv2d_depthwise_bias_fused_bn);
  %139 = maximum(%138, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %140 = minimum(%139, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %141 = nn.conv2d(%140, %efficientnet_lite4_model_blocks_12_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %142 = nn.bias_add(%141, %efficientnet_lite4_model_blocks_12_conv2d_1_Conv2D_bias_fused_bn);
  %143 = add(%142, %132);
  %144 = nn.conv2d(%143, %efficientnet_lite4_model_blocks_13_conv2d_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %145 = nn.bias_add(%144, %efficientnet_lite4_model_blocks_13_conv2d_Conv2D_bias_fused_bn);
  %146 = maximum(%145, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %147 = minimum(%146, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %148 = nn.conv2d(%147, %efficientnet_lite4_model_blocks_13_depthwise_conv2d_depthwise_weights_fused_bn, padding=[1, 1, 1, 1], groups=672, kernel_size=[3, 3]);
  %149 = nn.bias_add(%148, %efficientnet_lite4_model_blocks_13_depthwise_conv2d_depthwise_bias_fused_bn);
  %150 = maximum(%149, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %151 = minimum(%150, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %152 = nn.conv2d(%151, %efficientnet_lite4_model_blocks_13_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %153 = nn.bias_add(%152, %efficientnet_lite4_model_blocks_13_conv2d_1_Conv2D_bias_fused_bn);
  %154 = add(%153, %143);
  %155 = nn.conv2d(%154, %efficientnet_lite4_model_blocks_14_conv2d_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %156 = nn.bias_add(%155, %efficientnet_lite4_model_blocks_14_conv2d_Conv2D_bias_fused_bn);
  %157 = maximum(%156, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %158 = minimum(%157, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %159 = nn.conv2d(%158, %efficientnet_lite4_model_blocks_14_depthwise_conv2d_depthwise_weights_fused_bn, padding=[1, 1, 1, 1], groups=672, kernel_size=[3, 3]);
  %160 = nn.bias_add(%159, %efficientnet_lite4_model_blocks_14_depthwise_conv2d_depthwise_bias_fused_bn);
  %161 = maximum(%160, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %162 = minimum(%161, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %163 = nn.conv2d(%162, %efficientnet_lite4_model_blocks_14_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %164 = nn.bias_add(%163, %efficientnet_lite4_model_blocks_14_conv2d_1_Conv2D_bias_fused_bn);
  %165 = add(%164, %154);
  %166 = nn.conv2d(%165, %efficientnet_lite4_model_blocks_15_conv2d_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %167 = nn.bias_add(%166, %efficientnet_lite4_model_blocks_15_conv2d_Conv2D_bias_fused_bn);
  %168 = maximum(%167, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %169 = minimum(%168, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %170 = nn.conv2d(%169, %efficientnet_lite4_model_blocks_15_depthwise_conv2d_depthwise_weights_fused_bn, padding=[2, 2, 2, 2], groups=672, kernel_size=[5, 5]);
  %171 = nn.bias_add(%170, %efficientnet_lite4_model_blocks_15_depthwise_conv2d_depthwise_bias_fused_bn);
  %172 = maximum(%171, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %173 = minimum(%172, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %174 = nn.conv2d(%173, %efficientnet_lite4_model_blocks_15_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %175 = nn.bias_add(%174, %efficientnet_lite4_model_blocks_15_conv2d_1_Conv2D_bias_fused_bn);
  %176 = nn.conv2d(%175, %efficientnet_lite4_model_blocks_16_conv2d_Conv2D_ReadVariableOp_0, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %177 = nn.batch_norm(%176, %efficientnet_lite4_model_blocks_16_tpu_batch_normalization_ReadVariableOp_0, %efficientnet_lite4_model_blocks_16_tpu_batch_normalization_ReadVariableOp_1_0, %efficientnet_lite4_model_blocks_16_tpu_batch_normalization_FusedBatchNormV3_ReadVariableOp_0, %efficientnet_lite4_model_blocks_16_tpu_batch_normalization_FusedBatchNormV3_ReadVariableOp_1_0, epsilon=0.001f);
  %178 = %177.0;
  %179 = maximum(%178, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %180 = minimum(%179, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %181 = nn.conv2d(%180, %efficientnet_lite4_model_blocks_16_depthwise_conv2d_depthwise_weights_fused_bn, padding=[2, 2, 2, 2], groups=960, kernel_size=[5, 5]);
  %182 = nn.bias_add(%181, %efficientnet_lite4_model_blocks_16_depthwise_conv2d_depthwise_bias_fused_bn);
  %183 = maximum(%182, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %184 = minimum(%183, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %185 = nn.conv2d(%184, %efficientnet_lite4_model_blocks_16_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %186 = nn.bias_add(%185, %efficientnet_lite4_model_blocks_16_conv2d_1_Conv2D_bias_fused_bn);
  %187 = add(%186, %175);
  %188 = nn.conv2d(%187, %efficientnet_lite4_model_blocks_17_conv2d_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %189 = nn.bias_add(%188, %efficientnet_lite4_model_blocks_17_conv2d_Conv2D_bias_fused_bn);
  %190 = maximum(%189, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %191 = minimum(%190, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %192 = nn.conv2d(%191, %efficientnet_lite4_model_blocks_17_depthwise_conv2d_depthwise_weights_fused_bn, padding=[2, 2, 2, 2], groups=960, kernel_size=[5, 5]);
  %193 = nn.bias_add(%192, %efficientnet_lite4_model_blocks_17_depthwise_conv2d_depthwise_bias_fused_bn);
  %194 = maximum(%193, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %195 = minimum(%194, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %196 = nn.conv2d(%195, %efficientnet_lite4_model_blocks_17_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %197 = nn.bias_add(%196, %efficientnet_lite4_model_blocks_17_conv2d_1_Conv2D_bias_fused_bn);
  %198 = add(%197, %187);
  %199 = nn.conv2d(%198, %efficientnet_lite4_model_blocks_18_conv2d_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %200 = nn.bias_add(%199, %efficientnet_lite4_model_blocks_18_conv2d_Conv2D_bias_fused_bn);
  %201 = maximum(%200, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %202 = minimum(%201, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %203 = nn.conv2d(%202, %efficientnet_lite4_model_blocks_18_depthwise_conv2d_depthwise_weights_fused_bn, padding=[2, 2, 2, 2], groups=960, kernel_size=[5, 5]);
  %204 = nn.bias_add(%203, %efficientnet_lite4_model_blocks_18_depthwise_conv2d_depthwise_bias_fused_bn);
  %205 = maximum(%204, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %206 = minimum(%205, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %207 = nn.conv2d(%206, %efficientnet_lite4_model_blocks_18_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %208 = nn.bias_add(%207, %efficientnet_lite4_model_blocks_18_conv2d_1_Conv2D_bias_fused_bn);
  %209 = add(%208, %198);
  %210 = nn.conv2d(%209, %efficientnet_lite4_model_blocks_19_conv2d_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %211 = nn.bias_add(%210, %efficientnet_lite4_model_blocks_19_conv2d_Conv2D_bias_fused_bn);
  %212 = maximum(%211, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %213 = minimum(%212, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %214 = nn.conv2d(%213, %efficientnet_lite4_model_blocks_19_depthwise_conv2d_depthwise_weights_fused_bn, padding=[2, 2, 2, 2], groups=960, kernel_size=[5, 5]);
  %215 = nn.bias_add(%214, %efficientnet_lite4_model_blocks_19_depthwise_conv2d_depthwise_bias_fused_bn);
  %216 = maximum(%215, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %217 = minimum(%216, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %218 = nn.conv2d(%217, %efficientnet_lite4_model_blocks_19_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %219 = nn.bias_add(%218, %efficientnet_lite4_model_blocks_19_conv2d_1_Conv2D_bias_fused_bn);
  %220 = add(%219, %209);
  %221 = nn.conv2d(%220, %efficientnet_lite4_model_blocks_20_conv2d_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %222 = nn.bias_add(%221, %efficientnet_lite4_model_blocks_20_conv2d_Conv2D_bias_fused_bn);
  %223 = maximum(%222, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %224 = minimum(%223, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %225 = nn.conv2d(%224, %efficientnet_lite4_model_blocks_20_depthwise_conv2d_depthwise_weights_fused_bn, padding=[2, 2, 2, 2], groups=960, kernel_size=[5, 5]);
  %226 = nn.bias_add(%225, %efficientnet_lite4_model_blocks_20_depthwise_conv2d_depthwise_bias_fused_bn);
  %227 = maximum(%226, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %228 = minimum(%227, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %229 = nn.conv2d(%228, %efficientnet_lite4_model_blocks_20_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %230 = nn.bias_add(%229, %efficientnet_lite4_model_blocks_20_conv2d_1_Conv2D_bias_fused_bn);
  %231 = add(%230, %220);
  %232 = nn.conv2d(%231, %efficientnet_lite4_model_blocks_21_conv2d_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %233 = nn.bias_add(%232, %efficientnet_lite4_model_blocks_21_conv2d_Conv2D_bias_fused_bn);
  %234 = maximum(%233, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %235 = minimum(%234, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %236 = nn.conv2d(%235, %efficientnet_lite4_model_blocks_21_depthwise_conv2d_depthwise_weights_fused_bn, strides=[2, 2], padding=[1, 1, 2, 2], groups=960, kernel_size=[5, 5]);
  %237 = nn.bias_add(%236, %efficientnet_lite4_model_blocks_21_depthwise_conv2d_depthwise_bias_fused_bn);
  %238 = maximum(%237, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %239 = minimum(%238, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %240 = nn.conv2d(%239, %efficientnet_lite4_model_blocks_21_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %241 = nn.bias_add(%240, %efficientnet_lite4_model_blocks_21_conv2d_1_Conv2D_bias_fused_bn);
  %242 = nn.conv2d(%241, %efficientnet_lite4_model_blocks_22_conv2d_Conv2D_ReadVariableOp_0, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %243 = nn.batch_norm(%242, %efficientnet_lite4_model_blocks_22_tpu_batch_normalization_ReadVariableOp_0, %efficientnet_lite4_model_blocks_22_tpu_batch_normalization_ReadVariableOp_1_0, %efficientnet_lite4_model_blocks_22_tpu_batch_normalization_FusedBatchNormV3_ReadVariableOp_0, %efficientnet_lite4_model_blocks_22_tpu_batch_normalization_FusedBatchNormV3_ReadVariableOp_1_0, epsilon=0.001f);
  %244 = %243.0;
  %245 = maximum(%244, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %246 = minimum(%245, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %247 = nn.conv2d(%246, %efficientnet_lite4_model_blocks_22_depthwise_conv2d_depthwise_weights_fused_bn, padding=[2, 2, 2, 2], groups=1632, kernel_size=[5, 5]);
  %248 = nn.bias_add(%247, %efficientnet_lite4_model_blocks_22_depthwise_conv2d_depthwise_bias_fused_bn);
  %249 = maximum(%248, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %250 = minimum(%249, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %251 = nn.conv2d(%250, %efficientnet_lite4_model_blocks_22_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %252 = nn.bias_add(%251, %efficientnet_lite4_model_blocks_22_conv2d_1_Conv2D_bias_fused_bn);
  %253 = add(%252, %241);
  %254 = nn.conv2d(%253, %efficientnet_lite4_model_blocks_23_conv2d_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %255 = nn.bias_add(%254, %efficientnet_lite4_model_blocks_23_conv2d_Conv2D_bias_fused_bn);
  %256 = maximum(%255, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %257 = minimum(%256, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %258 = nn.conv2d(%257, %efficientnet_lite4_model_blocks_23_depthwise_conv2d_depthwise_weights_fused_bn, padding=[2, 2, 2, 2], groups=1632, kernel_size=[5, 5]);
  %259 = nn.bias_add(%258, %efficientnet_lite4_model_blocks_23_depthwise_conv2d_depthwise_bias_fused_bn);
  %260 = maximum(%259, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %261 = minimum(%260, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %262 = nn.conv2d(%261, %efficientnet_lite4_model_blocks_23_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %263 = nn.bias_add(%262, %efficientnet_lite4_model_blocks_23_conv2d_1_Conv2D_bias_fused_bn);
  %264 = add(%263, %253);
  %265 = nn.conv2d(%264, %efficientnet_lite4_model_blocks_24_conv2d_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %266 = nn.bias_add(%265, %efficientnet_lite4_model_blocks_24_conv2d_Conv2D_bias_fused_bn);
  %267 = maximum(%266, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %268 = minimum(%267, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %269 = nn.conv2d(%268, %efficientnet_lite4_model_blocks_24_depthwise_conv2d_depthwise_weights_fused_bn, padding=[2, 2, 2, 2], groups=1632, kernel_size=[5, 5]);
  %270 = nn.bias_add(%269, %efficientnet_lite4_model_blocks_24_depthwise_conv2d_depthwise_bias_fused_bn);
  %271 = maximum(%270, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %272 = minimum(%271, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %273 = nn.conv2d(%272, %efficientnet_lite4_model_blocks_24_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %274 = nn.bias_add(%273, %efficientnet_lite4_model_blocks_24_conv2d_1_Conv2D_bias_fused_bn);
  %275 = add(%274, %264);
  %276 = nn.conv2d(%275, %efficientnet_lite4_model_blocks_25_conv2d_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %277 = nn.bias_add(%276, %efficientnet_lite4_model_blocks_25_conv2d_Conv2D_bias_fused_bn);
  %278 = maximum(%277, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %279 = minimum(%278, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %280 = nn.conv2d(%279, %efficientnet_lite4_model_blocks_25_depthwise_conv2d_depthwise_weights_fused_bn, padding=[2, 2, 2, 2], groups=1632, kernel_size=[5, 5]);
  %281 = nn.bias_add(%280, %efficientnet_lite4_model_blocks_25_depthwise_conv2d_depthwise_bias_fused_bn);
  %282 = maximum(%281, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %283 = minimum(%282, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %284 = nn.conv2d(%283, %efficientnet_lite4_model_blocks_25_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %285 = nn.bias_add(%284, %efficientnet_lite4_model_blocks_25_conv2d_1_Conv2D_bias_fused_bn);
  %286 = add(%285, %275);
  %287 = nn.conv2d(%286, %efficientnet_lite4_model_blocks_26_conv2d_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %288 = nn.bias_add(%287, %efficientnet_lite4_model_blocks_26_conv2d_Conv2D_bias_fused_bn);
  %289 = maximum(%288, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %290 = minimum(%289, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %291 = nn.conv2d(%290, %efficientnet_lite4_model_blocks_26_depthwise_conv2d_depthwise_weights_fused_bn, padding=[2, 2, 2, 2], groups=1632, kernel_size=[5, 5]);
  %292 = nn.bias_add(%291, %efficientnet_lite4_model_blocks_26_depthwise_conv2d_depthwise_bias_fused_bn);
  %293 = maximum(%292, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %294 = minimum(%293, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %295 = nn.conv2d(%294, %efficientnet_lite4_model_blocks_26_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %296 = nn.bias_add(%295, %efficientnet_lite4_model_blocks_26_conv2d_1_Conv2D_bias_fused_bn);
  %297 = add(%296, %286);
  %298 = nn.conv2d(%297, %efficientnet_lite4_model_blocks_27_conv2d_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %299 = nn.bias_add(%298, %efficientnet_lite4_model_blocks_27_conv2d_Conv2D_bias_fused_bn);
  %300 = maximum(%299, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %301 = minimum(%300, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %302 = nn.conv2d(%301, %efficientnet_lite4_model_blocks_27_depthwise_conv2d_depthwise_weights_fused_bn, padding=[2, 2, 2, 2], groups=1632, kernel_size=[5, 5]);
  %303 = nn.bias_add(%302, %efficientnet_lite4_model_blocks_27_depthwise_conv2d_depthwise_bias_fused_bn);
  %304 = maximum(%303, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %305 = minimum(%304, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %306 = nn.conv2d(%305, %efficientnet_lite4_model_blocks_27_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %307 = nn.bias_add(%306, %efficientnet_lite4_model_blocks_27_conv2d_1_Conv2D_bias_fused_bn);
  %308 = add(%307, %297);
  %309 = nn.conv2d(%308, %efficientnet_lite4_model_blocks_28_conv2d_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %310 = nn.bias_add(%309, %efficientnet_lite4_model_blocks_28_conv2d_Conv2D_bias_fused_bn);
  %311 = maximum(%310, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %312 = minimum(%311, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %313 = nn.conv2d(%312, %efficientnet_lite4_model_blocks_28_depthwise_conv2d_depthwise_weights_fused_bn, padding=[2, 2, 2, 2], groups=1632, kernel_size=[5, 5]);
  %314 = nn.bias_add(%313, %efficientnet_lite4_model_blocks_28_depthwise_conv2d_depthwise_bias_fused_bn);
  %315 = maximum(%314, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %316 = minimum(%315, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %317 = nn.conv2d(%316, %efficientnet_lite4_model_blocks_28_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %318 = nn.bias_add(%317, %efficientnet_lite4_model_blocks_28_conv2d_1_Conv2D_bias_fused_bn);
  %319 = add(%318, %308);
  %320 = nn.conv2d(%319, %efficientnet_lite4_model_blocks_29_conv2d_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %321 = nn.bias_add(%320, %efficientnet_lite4_model_blocks_29_conv2d_Conv2D_bias_fused_bn);
  %322 = maximum(%321, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %323 = minimum(%322, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %324 = nn.conv2d(%323, %efficientnet_lite4_model_blocks_29_depthwise_conv2d_depthwise_weights_fused_bn, padding=[1, 1, 1, 1], groups=1632, kernel_size=[3, 3]);
  %325 = nn.bias_add(%324, %efficientnet_lite4_model_blocks_29_depthwise_conv2d_depthwise_bias_fused_bn);
  %326 = maximum(%325, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %327 = minimum(%326, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %328 = nn.conv2d(%327, %efficientnet_lite4_model_blocks_29_conv2d_1_Conv2D_weights_fused_bn, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %329 = nn.bias_add(%328, %efficientnet_lite4_model_blocks_29_conv2d_1_Conv2D_bias_fused_bn);
  %330 = nn.conv2d(%329, %efficientnet_lite4_model_head_conv2d_Conv2D_ReadVariableOp_0, padding=[0, 0, 0, 0], kernel_size=[1, 1]);
  %331 = nn.batch_norm(%330, %efficientnet_lite4_model_head_tpu_batch_normalization_ReadVariableOp_0, %efficientnet_lite4_model_head_tpu_batch_normalization_ReadVariableOp_1_0, %efficientnet_lite4_model_head_tpu_batch_normalization_FusedBatchNormV3_ReadVariableOp_0, %efficientnet_lite4_model_head_tpu_batch_normalization_FusedBatchNormV3_ReadVariableOp_1_0, epsilon=0.001f);
  %332 = %331.0;
  %333 = maximum(%332, %efficientnet_lite4_model_blocks_29_Relu6_1_min__569);
  %334 = minimum(%333, %efficientnet_lite4_model_blocks_19_Relu6_1_max__380);
  %335 = nn.avg_pool2d(%334, pool_size=[7, 7], padding=[0, 0, 0, 0]);
  %336 = squeeze(%335, axis=[2, 3]);
  %337 = transpose(%efficientnet_lite4_model_head_dense_MatMul_ReadVariableOp_0, axes=[1, 0]);
  %338 = nn.dense(%336, %337, units=None);
  %339 = add(%338, %efficientnet_lite4_model_head_dense_BiasAdd_ReadVariableOp_0);
  nn.softmax(%339, axis=1)
}
